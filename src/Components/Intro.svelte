<script>
</script>

<section>
  <p class="body-text">
    <a href="https://www.ibm.com/topics/knn">K-nearest neighbors (KNN)</a>
    algorithm is one of the simplest classification and regression classifiers. It
    is a non-parametric algorithm, which means that it does not assume any specific
    data distribution. It operates based on the idea that similar data points are
    close to each other in a multi-dimensional space. KNN classifies a new data point
    based on the majority class of its 'k' nearest neighbors. 'k' controls the complexity
    of the decision boundary, thus influencing the overall performance of the model.
    When k is small, the decision boundary tends to be more complex, following the
    contours of training data more closely; as k increases, the decision boundary
    tends to be smoother and simpler. Choosing the right k helps balance between
    overfitting and underfitting.
  </p>
</section>

<style>
</style>
